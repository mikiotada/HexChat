import sys
import os
import pandas as pd
import numpy as np
from collections import Counter

sys.path.append(os.path.split(os.getcwd())[0] + "/flask_backend")
from utility_be import validate_json, form_group_schema

##########################################
#######Helper functions to create subgroups
##########################################

def inverted_index(data, col_name, val_type, uid_field_name="index"):
    """
    Create inverted index based on pandas data
    
    Args:
        data [pd.DataFrame]: expect user tables
        col_name [str]: expect one of the cols in data.columns
        val_type [str]: 'MULT' / 'SINGLE', describe the data structure of a cell
        uid_field_name [str]: specify which column is uid, currently use 'index' as default
    """
    # Assertion
    assert isinstance(data, pd.DataFrame)
    assert col_name in data.columns
    assert val_type in ["MULT", "SINGLE"]

    # MULTIPLE eg, language: ['Spanish' 'Cantonese'], it contains mult. values
    if val_type == "MULT":
        ########
        # FIXME
        ########
        # basically this will flatten the list of list in pandas settings.
        # it looks complicated because pandas kind of change the format, fuck it
        # if you have better / clean solution, welcome to fix it
        lst = sum(
            [
                item.split("' '" or "\n ")
                for item in [item.strip("[]") for item in data[col_name]]
            ],
            [],
        )
        lst = [item.replace("'", "") for item in lst]
        lst = sum([item.split(', ') for item in lst if item.split(', ') != ''], [])
        key_lst = list(Counter(lst).keys())
        result = dict()

        for key in key_lst:
            result[key] = set(
                [
                    i
                    for i, val in zip(
                        data[uid_field_name],
                        [key in row_list for row_list in data[col_name]],
                    )
                    if val
                ]
            )

        return result

    # SINGLE eg, industry: Management Consulting, it is only single value
    if val_type == "SINGLE":
        # logic is simpler since it doesn't have any column
        lst = data[col_name]

        key_lst = list(Counter(lst).keys())
        result = dict()

        for key in key_lst:
            result[key] = set(
                [
                    i
                    for i, val in zip(
                        data[uid_field_name],
                        [key == row_list for row_list in data[col_name]],
                    )
                    if val
                ]
            )

        return result


def combined_inverted_index(data, ii_input, uid_field_name="index"):
    """
    result dict of inverted index
    Args:
        data [pd.DataFrame]: expect pandas.DataFrame
        ii_input [list of tuple]: inverted index input
            for each tuple, 
            tuple[0] is col name in data, 
            tuple[1] is val_type as specified in def:inverted_index
    """
    # Assert the first the first item in tuple belongs to data.columns
    assert np.all([item in data.columns for item in [item[0] for item in ii_input]])
    assert np.all(
        [item in ["SINGLE", "MULT"] for item in [item[1] for item in ii_input]]
    )

    result = dict()
    for item in ii_input:
        result[item[0]] = inverted_index(data, *item, uid_field_name)
    return result


# ii_input example
# ii_input = [
#     ('school', 'MULT'),
#     ('grad_yr', 'MULT'),
#     ('language', 'MULT'),
#     ('subject', 'SINGLE'),
#     ('zip', 'SINGLE'),
#     ('industry', 'SINGLE'),
#     ('title', 'SINGLE'),
#     ('country', 'SINGLE'),
# ]

def two_category_pair(combined_inverted_data, top_category='priority_tags'):
    """
    use one column as seed, try to explore another level
    """
    result = list()

    for key, ids in combined_inverted_data[top_category].items():
        if key != '':
            for category in combined_inverted_data.keys():
                if category != top_category:
                    for sub_key, sub_ids in combined_inverted_data[category].items():
                        if len(ids.intersection(sub_ids)) != 0 and sub_key != '':
                            result.append([
                                [top_category, category]
                                ,[str(key), str(sub_key)]
                                ,len(ids.intersection(sub_ids))
                                ,ids.intersection(sub_ids)
                            ])

    return result

def create_two_category_pair(data, ids_in_subgroups, ii_input, priority_key='priority_tags'):
    """
    use a fixed key and with another key in ii_input to create list of list
    Think of this as intersection of two sets where one set is fixed
    eg: this is the combination of priority_tags:tag_18 and language:Korean
        [['priority_tags', 'language'], ['tag_18', 'Korean'], 3, {16, 17, 53}]
    
    """
    remain_data = combined_inverted_index(data.iloc[data.index.isin(list(set(data['index']) - ids_in_subgroups))], ii_input)
    return two_category_pair(remain_data, priority_key)

def is_connected_before(data, valid_ids={0, 1, 8, 10}):
    """
    When form the subgroups, we don't want to group those connected (or met)
    If the subgroup has only two ppl, we require they haven't met before
    If the subgroup has more than 2 ppl, we require they know one at most
    """
    
    # if subgroup is two ppl
    if len(valid_ids) == 2:
        threshold = 0
    # if subgroup is more than two ppl
    else:
        threshold = 1
    # Pandas shit, it changed the data structure, anyway what this does is:
    #    for each uid in valid_ids, use their connected field to check again subgroups
    #    eg: [0, 0, 1, 2] <- user 3 knows one ppl in the group, user 4 knows two ppl in the group
    tmp = [len(valid_ids.intersection(set([int(item) for item in data.iloc[i].connected[1:-1].split(' ') if item != '']))) for i in valid_ids]
    
    return max(tmp) > threshold

def break_to_subgroups(num=19):
    """
    Break the numbers to be consisted of 2 or 3 or 4 only
    """
    
    result = list()
    if num == 4:
        return [4]
    elif num == 5:
        return [2, 3]
    elif num == 6:
        return [3, 3]

    else:
        result.append([3])
        result.append(break_to_subgroups(num-3))
    return [item for sublist in result for item in sublist]

def remain_users(data, ids_processed, uid_field_name='index'):
    """
    based on current processed uid, get the pandas for the remaining users
    """
    return data.loc[~data['index'].isin(ids_processed)]

##########################################
#######Helper functions to combine subgroups
##########################################
def subgroup_compare(subgroup_1, subgroup_2):
    pair = dict()
    
    pair['subgroup_keys'] = set().union(subgroup_1[0], subgroup_2[0])
    pair['subgroup_uids'] = set().union(subgroup_1[3], subgroup_2[3])
    pair['each_uids'] = [subgroup_1[3], subgroup_2[3]]
    return pair

# pair = subgroup_compare(subgroups[0], subgroups[1])
# pair

def decide_merge_subgroups(data, ii_input, priority_keys, pair, similarity_shared_by=3):
    tmp = combined_inverted_index(data.loc[data['index'].isin(list(pair['subgroup_uids']))], ii_input)

    # we want to merge the subgroups, each subgroup is grouped by its own reason
    # we need to find other similarity b/w both to combine them

    # explore other cols
    for key in set(priority_keys) - pair['subgroup_keys']:

        for item in tmp[key].items():
            # A similarity is shared by 3 + ppl
            if len(item[1]) >= similarity_shared_by and len(item[1]-pair['each_uids'][0]) != 0 and len(item[1]-pair['each_uids'][1]) != 0:
                print(f'Group of {len(pair["subgroup_uids"])} ppl is formed based on {key}')
                return True
            else:
                return False

def decide_merge_single_user(data, priority_keys, ii_input, group_set, individual_set, similarity_cnt_threshold=2, similarity_shared_by=3):
    # if new fd <= 2, don't merge
    if len(group_set - (set([int(item) for item in data.iloc[individual_set].connected[1:-1].split(' ') if item != '']))) <= 2:
        return False
    
    similarity_count = 0
    tmp = combined_inverted_index(data.loc[data['index'].isin(list(group_set.union({individual_set})))], ii_input)
    for key in set(priority_keys):
        
        for item in tmp[key].items():
            # A similarity is shared by 3 + ppl and include single user
            if len(item[1]) >= similarity_shared_by and len(item[1]-{individual_set}) != 0:
                similarity_count += 1

    # 2 similarity
    if similarity_count >= similarity_cnt_threshold:
        return True
    else:
        return False        

def which_group(data, priority_keys, ii_input, groups, uid, similarity_cnt_threshold=2, similarity_shared_by=3):    
    lst = list(enumerate([(decide_merge_single_user(data, priority_keys, ii_input, group, uid, similarity_cnt_threshold, similarity_shared_by), len(group)) for group in groups]))
    
    for i in [4, 5, 6]:
        res = [item for item in lst if item[1][0] and item[1][1]==i]
        if res == []:
            pass
        else:
            return res[0][0]
    return -1

class FormGroupHelper:
    """
    This class is aim to prepare the data for forming the chatgroup
    Current input is arbitrary but we just adjust later, this is to
    help algorithm side, to avoid they break the group creation logic
    """

    def __init__(
        self, name: str, user_ids: list, welcome_str: dict, ending_str: list,
    ):

        """
        arbitrary for the moment, ok to adjust
        """
        self.name = name
        self.user_ids = user_ids
        self.welcome_str = welcome_str
        self.ending_str = ending_str
        self.json_schema = form_group_schema

    def _make_data(self) -> dict:
        """
        We need to impose the schema here and corresponding validator
        JSON validator will be the gatekeeper to perform check in this 
        Class before making the data and in form_group_API
        """
        return {
            "name": self.name,
            "user_ids": self.user_ids,
            "test_str": {
                "welcome_str": self.welcome_str,
                "ending_str": self.ending_str,
            },
        }

    def validate_data_for_API(self) -> bool:
        """
        helper function to return boolean result
        True: pass the validation
        False: fail to pass the validation
        """
        data = self._make_data()
        if validate_json(data, self.json_schema):
            return True
        else:
            return False

    def prepare_data_for_API(self):
        """
        function to create the data, validate it and export if every step is fine
        """
        if self.validate_data_for_API():
            # TODO: attach unique identifier for each group
            # maybe based on time? or hash?
            return self._make_data()
